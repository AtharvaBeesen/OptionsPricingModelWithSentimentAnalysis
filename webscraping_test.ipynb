{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e407d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ea7493",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e27b517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c175ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import requests as req\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean_text(text):\n",
    "  \"\"\"\n",
    "  Cleans and preprocesses text data, keeping percentages and numbers.\n",
    "\n",
    "  Args:\n",
    "      text (str): The text to be cleaned.\n",
    "\n",
    "  Returns:\n",
    "      list: A list of cleaned and lemmatized words.\n",
    "  \"\"\"\n",
    "  # Lowercase\n",
    "  text = text.lower()\n",
    "  # Remove HTML tags\n",
    "  text = BS(text, \"html.parser\").get_text(separator=\" \")\n",
    "  # Remove special characters, keeping alphanumeric, whitespace, and percentages\n",
    "  import re\n",
    "  text = re.sub(r\"[^a-zA-Z0-9\\s%]\", \"\", text)\n",
    "  # Tokenize into words, considering percentages and numbers with periods as single tokens\n",
    "  tokens = re.findall(r\"[a-zA-Z]+|\\d+(?:\\.\\d+)?%|\\d+\\.\\d+|[0-9]+\", text)\n",
    "\n",
    "  # Data Preprocessing Enhancements:\n",
    "\n",
    "  # 1. Filtering (Optional): You can add logic here to filter unwanted entries.\n",
    "  #    For example, filter out entries with very short text snippets (less than X words).\n",
    "  #    filtered_tokens = [token for token in tokens if len(token) > 5]  # Example filter\n",
    "\n",
    "  # 2. Remove Links (Optional): If you only want the core text, remove links.\n",
    "  #    tokens = [token for token in tokens if not token.startswith(\"http\")]\n",
    "\n",
    "  # 3. Remove Stopwords\n",
    "  stop_words = stopwords.words(\"english\")\n",
    "  tokens = [token for token in tokens if token not in stopwords]\n",
    "\n",
    "  # 4. Lemmatization (replace with stemming if preferred)\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  stop_words = stopwords.words(\"english\")  # Get stopwords as a list\n",
    "  tokens = [token for token in tokens if token not in stop_words]\n",
    "  return tokens\n",
    "\n",
    "# Define URLs for each website\n",
    "urls = [\n",
    "  \"https://www.businesstoday.in/latest/economy\",\n",
    "  \"https://www.cnbc.com/finance/\",\n",
    "  \"https://seekingalpha.com/\"\n",
    "]\n",
    "\n",
    "# Loop through each URL\n",
    "for url in urls:\n",
    "  webpage = req.get(url)\n",
    "  soup = BS(webpage.content, \"html.parser\")\n",
    "  M = 1\n",
    "  for link in soup.find_all('a'):\n",
    "    if str(type(link.string)) == \"<class 'bs4.element.NavigableString'>\" and len(link.string) > 35:\n",
    "      # Focus on the text content of the snippet, excluding the link itself (Optional)\n",
    "      cleaned_text = clean_text(link.string.strip())  # Remove potential leading/trailing whitespace\n",
    "      print(f\"{M}.\", \" \".join(cleaned_text))\n",
    "      M += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
